{"cells":[{"cell_type":"code","execution_count":148,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-11T15:34:17.845707Z","iopub.status.busy":"2024-10-11T15:34:17.845245Z","iopub.status.idle":"2024-10-11T15:34:17.861497Z","shell.execute_reply":"2024-10-11T15:34:17.860252Z","shell.execute_reply.started":"2024-10-11T15:34:17.845660Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Importing Libraries, reading and understanding the data"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:43.111027Z","iopub.status.busy":"2024-10-11T15:34:43.110420Z","iopub.status.idle":"2024-10-11T15:34:43.117343Z","shell.execute_reply":"2024-10-11T15:34:43.116113Z","shell.execute_reply.started":"2024-10-11T15:34:43.110963Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:45.207146Z","iopub.status.busy":"2024-10-11T15:34:45.206697Z","iopub.status.idle":"2024-10-11T15:34:45.579852Z","shell.execute_reply":"2024-10-11T15:34:45.578647Z","shell.execute_reply.started":"2024-10-11T15:34:45.207105Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/Users/aditya/data-mining/adult_data.csv')\n","df_test = pd.read_csv('/Users/aditya/data-mining/adult_test.csv')\n","data_descr = pd.read_csv('/Users/aditya/data-mining/adult_descr.csv', sep=':')\n","\n","data_names = data_descr.tail(15)\n","names = list(data_names.index)\n","\n","# move the first column on the last position\n","names.append(names[0])\n","names = names[1:]\n","\n","df = pd.read_csv('/Users/aditya/data-mining/adult_data.csv', names=names)\n","df = df.rename(columns={',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,': 'income'})\n","df.head(15)\n","\n","df_test = pd.read_csv('/Users/aditya/data-mining/adult_test.csv', names=names)\n","df_test = df_test.rename(columns={',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,': 'income'})\n","df_test = df_test.iloc[1:]\n","df_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.countplot(x='income', data=df, palette='pastel')"]},{"cell_type":"markdown","metadata":{},"source":["Pointing out missing data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:47.603198Z","iopub.status.busy":"2024-10-11T15:34:47.602743Z","iopub.status.idle":"2024-10-11T15:34:47.711258Z","shell.execute_reply":"2024-10-11T15:34:47.710068Z","shell.execute_reply.started":"2024-10-11T15:34:47.603156Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Assuming df is your DataFrame\n","total_rows = len(df)\n","\n","# Check frequency of '?' in each column\n","missing_freq = (df == ' ?').sum()\n","\n","# Calculate percentage of missing data\n","missing_percentage = (missing_freq / total_rows) * 100\n","\n","# Display results for columns with missing data\n","for column in missing_freq.index:\n","    if missing_freq[column] > 0:\n","        print(f\"{column}:\")\n","        print(f\"  Number of '?': {missing_freq[column]}\")\n","        print(f\"  Percentage: {missing_percentage[column]:.2f}%\")\n","        print(f\"  Mode (replacement value): {df[column].mode()[0]}\")\n","        print()\n","\n","# Calculate total percentage of rows with any missing data\n","rows_with_missing = df.isin([' ?']).any(axis=1).sum()\n","total_missing_percentage = (rows_with_missing / total_rows) * 100\n","\n","print(f\"Total rows with any missing data: {rows_with_missing}\")\n","print(f\"Percentage of dataset affected: {total_missing_percentage:.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["Replacing missing data with mode"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:52.637680Z","iopub.status.busy":"2024-10-11T15:34:52.637200Z","iopub.status.idle":"2024-10-11T15:34:52.682033Z","shell.execute_reply":"2024-10-11T15:34:52.680891Z","shell.execute_reply.started":"2024-10-11T15:34:52.637638Z"},"trusted":true},"outputs":[],"source":["df['workclass'] = df['workclass'].replace(' ?', 'Private')\n","df['occupation'] = df['occupation'].replace(' ?', 'Prof-specialty')\n","df['native-country'] = df['native-country'].replace(' ?', 'United-States')\n","df.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:55.068143Z","iopub.status.busy":"2024-10-11T15:34:55.067704Z","iopub.status.idle":"2024-10-11T15:34:55.146504Z","shell.execute_reply":"2024-10-11T15:34:55.145131Z","shell.execute_reply.started":"2024-10-11T15:34:55.068106Z"},"trusted":true},"outputs":[],"source":["\n","df_test['workclass'] = df_test['workclass'].replace(' ?', 'Private')\n","df_test['occupation'] = df_test['occupation'].replace(' ?', 'Prof-specialty')\n","df_test['native-country'] = df_test['native-country'].replace(' ?', 'United-States')\n","df_test.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:34:57.265941Z","iopub.status.busy":"2024-10-11T15:34:57.265094Z","iopub.status.idle":"2024-10-11T15:34:57.410930Z","shell.execute_reply":"2024-10-11T15:34:57.409790Z","shell.execute_reply.started":"2024-10-11T15:34:57.265895Z"},"trusted":true},"outputs":[],"source":["# education Category\n","df.education= df.education.replace([' Preschool', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th',' 10th', ' 11th', ' 12th'], 'School')\n","df.education = df.education.replace(' HS-grad', 'HighSchool-Grad')\n","df.education = df.education.replace([' Assoc-voc', ' Assoc-acdm', ' Prof-school', ' Some-college'], 'Higher')\n","df.education = df.education.replace('Bachelors', 'Undergrad')\n","df.education = df.education.replace('Masters', 'Grad')\n","df.education = df.education.replace('Doctorate', 'Doc')\n","\n","#martial status\n","df['marital-status']= df['marital-status'].replace([' Married-civ-spouse', ' Married-AF-spouse'], 'Married')\n","df['marital-status']= df['marital-status'].replace([' Never-married'], 'Not-married')\n","df['marital-status']= df['marital-status'].replace([' Divorced', ' Separated',' Widowed',\n","                                                   ' Married-spouse-absent'], ' Other')\n","\n","# income\n","df.income = df.income.replace(' <=50K', 0)\n","df.income = df.income.replace(' >50K', 1)\n","df.head(15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:01.043900Z","iopub.status.busy":"2024-10-11T15:35:01.042914Z","iopub.status.idle":"2024-10-11T15:35:01.135324Z","shell.execute_reply":"2024-10-11T15:35:01.134103Z","shell.execute_reply.started":"2024-10-11T15:35:01.043855Z"},"trusted":true},"outputs":[],"source":["df_test['fnlwgt'] = df_test['fnlwgt'].astype(int)\n","df_test['education-num'] = df_test['education-num'].astype(int)\n","df_test['capital-gain'] = df_test['capital-gain'].astype(int)\n","df_test['capital-loss'] = df_test['capital-loss'].astype(int)\n","df_test['hours-per-week'] = df_test['hours-per-week'].astype(int)\n","\n","# education Category\n","df_test.education= df_test.education.replace([' Preschool', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th',' 10th', ' 11th', ' 12th'], 'School')\n","df_test.education = df_test.education.replace(' HS-grad', 'HighSchool-Grad')\n","df_test.education = df_test.education.replace([' Assoc-voc', ' Assoc-acdm', ' Prof-school', ' Some-college'], 'Higher')\n","df_test.education = df_test.education.replace('Bachelors', 'Undergrad')\n","df_test.education = df_test.education.replace('Masters', 'Grad')\n","df_test.education = df_test.education.replace('Doctorate', 'Doc')\n","\n","#martial status\n","df_test['marital-status']= df_test['marital-status'].replace([' Married-civ-spouse', ' Married-AF-spouse'], 'Married')\n","df_test['marital-status']= df_test['marital-status'].replace([' Never-married'], 'Not-married')\n","df_test['marital-status']= df_test['marital-status'].replace([' Divorced', ' Separated',' Widowed',' Married-spouse-absent'], ' Other')\n","\n","# income\n","df_test.income = df_test.income.replace(' <=50K.', 0)\n","df_test.income = df_test.income.replace(' >50K.', 1)\n","df_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["Data transformation and Model building"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:07.048823Z","iopub.status.busy":"2024-10-11T15:35:07.048316Z","iopub.status.idle":"2024-10-11T15:35:07.175060Z","shell.execute_reply":"2024-10-11T15:35:07.174021Z","shell.execute_reply.started":"2024-10-11T15:35:07.048781Z"},"trusted":true},"outputs":[],"source":["X= df.drop(['income'], axis=1)\n","y = df['income']\n","\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","df1= df.copy()\n","df1= df1.apply(LabelEncoder().fit_transform)\n","df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:09.203457Z","iopub.status.busy":"2024-10-11T15:35:09.202977Z","iopub.status.idle":"2024-10-11T15:35:09.281086Z","shell.execute_reply":"2024-10-11T15:35:09.279441Z","shell.execute_reply.started":"2024-10-11T15:35:09.203412Z"},"trusted":true},"outputs":[],"source":["A= df_test.drop(['income'], axis=1)\n","b= df_test['income']\n","\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","df2= df_test.copy()\n","df2= df2.apply(LabelEncoder().fit_transform)\n","df2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:11.486123Z","iopub.status.busy":"2024-10-11T15:35:11.485534Z","iopub.status.idle":"2024-10-11T15:35:11.525894Z","shell.execute_reply":"2024-10-11T15:35:11.524770Z","shell.execute_reply.started":"2024-10-11T15:35:11.486071Z"},"trusted":true},"outputs":[],"source":["ss= StandardScaler().fit(df1.drop('income', axis=1))\n","X= ss.transform(df1.drop('income', axis=1))\n","y= df['income']\n","\n","df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:14.320667Z","iopub.status.busy":"2024-10-11T15:35:14.320160Z","iopub.status.idle":"2024-10-11T15:35:14.347227Z","shell.execute_reply":"2024-10-11T15:35:14.346084Z","shell.execute_reply.started":"2024-10-11T15:35:14.320622Z"},"trusted":true},"outputs":[],"source":["ssa= StandardScaler().fit(df2.drop('income', axis=1))\n","A= ssa.transform(df2.drop('income', axis=1))\n","b= df_test['income']\n","\n","df2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:16.489497Z","iopub.status.busy":"2024-10-11T15:35:16.488311Z","iopub.status.idle":"2024-10-11T15:35:16.572319Z","shell.execute_reply":"2024-10-11T15:35:16.570852Z","shell.execute_reply.started":"2024-10-11T15:35:16.489430Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train=X\n","y_train=y\n","A_test=A\n","b_test=b\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","lr = LogisticRegression()\n","\n","model = lr.fit(X_train, y_train)\n","prediction = model.predict(A_test)\n","\n","print(\"Acc on training data: {:,.3f}\".format(lr.score(X_train, y_train)))\n","print(\"Acc on test data: {:,.3f}\".format(lr.score(A_test, b_test)))"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:19.448491Z","iopub.status.busy":"2024-10-11T15:35:19.447629Z","iopub.status.idle":"2024-10-11T15:35:20.062012Z","shell.execute_reply":"2024-10-11T15:35:20.060445Z","shell.execute_reply.started":"2024-10-11T15:35:19.448445Z"},"trusted":true},"outputs":[],"source":["for i in range(10):   \n","    model = lr.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:25.038425Z","iopub.status.busy":"2024-10-11T15:35:25.037554Z","iopub.status.idle":"2024-10-11T15:35:30.964132Z","shell.execute_reply":"2024-10-11T15:35:30.962856Z","shell.execute_reply.started":"2024-10-11T15:35:25.038381Z"},"trusted":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rfc = RandomForestClassifier()\n","\n","model1 = rfc.fit(X_train, y_train)\n","prediction1 = model1.predict(A_test)\n","\n","print(\"Acc on training data: {:,.3f}\".format(rfc.score(X_train, y_train)))\n","print(\"Acc on test data: {:,.3f}\".format(rfc.score(A_test, b_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T15:35:30.966897Z","iopub.status.busy":"2024-10-11T15:35:30.966299Z","iopub.status.idle":"2024-10-11T15:36:11.674524Z","shell.execute_reply":"2024-10-11T15:36:11.673398Z","shell.execute_reply.started":"2024-10-11T15:35:30.966845Z"},"trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","# Initialize KNN classifier\n","knn = KNeighborsClassifier(n_neighbors=5)  \n","\n","# Fit the model\n","model2 = knn.fit(X_train, y_train)\n","\n","# Make predictions\n","prediction2 = model2.predict(A_test)\n","\n","# Print accuracies\n","print(\"KNN Acc on training data: {:,.3f}\".format(knn.score(X_train, y_train)))\n","print(\"KNN Acc on test data: {:,.3f}\".format(knn.score(A_test, b_test)))"]},{"cell_type":"markdown","metadata":{},"source":["Hyperparameter tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-11T15:34:19.195898Z","iopub.status.idle":"2024-10-11T15:34:19.196472Z","shell.execute_reply":"2024-10-11T15:34:19.196210Z","shell.execute_reply.started":"2024-10-11T15:34:19.196180Z"},"trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming X_train, X_test, y_train, y_test are your data splits\n","\n","# Define the parameter grid\n","param_grid = {\n","    'n_neighbors': [3, 5, 7, 9, 11],  # Include your current best (5)\n","    'weights': ['uniform', 'distance'],\n","    'metric': ['euclidean', 'manhattan', 'minkowski'],\n","    'p': [1, 2]  # 1 for manhattan, 2 for euclidean\n","}\n","\n","# Create the KNN classifier\n","knn = KNeighborsClassifier()\n","\n","# Set up GridSearchCV\n","grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","# Fit the grid search\n","grid_search.fit(X_train, y_train)\n","\n","# Print the best parameters and score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best cross-validation score:\", grid_search.best_score_)\n","\n","# Use the best model to make predictions\n","best_knn = grid_search.best_estimator_\n","y_pred = best_knn.predict(A_test)\n","\n","# Calculate and print the test accuracy\n","test_accuracy = accuracy_score(b_test, y_pred)\n","print(\"Test accuracy with best parameters:\", test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T16:12:23.931178Z","iopub.status.busy":"2024-10-11T16:12:23.930645Z","iopub.status.idle":"2024-10-11T16:14:15.848732Z","shell.execute_reply":"2024-10-11T16:14:15.847404Z","shell.execute_reply.started":"2024-10-11T16:12:23.931133Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import accuracy_score, classification_report\n","import time\n","\n","# Assuming X_train, y_train, A_test, and b_test are already defined\n","\n","# Define a smaller parameter grid for RandomizedSearchCV\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_features': ['sqrt', 'log2'],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'bootstrap': [True, False]\n","}\n","\n","# Create a base model with max_features explicitly set to 'sqrt'\n","rf = RandomForestClassifier(random_state=42, max_features='sqrt')\n","\n","# Instantiate the RandomizedSearchCV object with fewer iterations\n","rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=20, cv=3, \n","                               verbose=2, random_state=42, n_jobs=-1)\n","\n","# Fit the random search model\n","start_time = time.time()\n","rf_random.fit(X_train, y_train)\n","train_time = time.time() - start_time\n","\n","print(\"Best parameters found: \", rf_random.best_params_)\n","print(f\"Training time: {train_time:.2f} seconds\")\n","\n","# Calculate and print training accuracy\n","y_train_pred = rf_random.predict(X_train)\n","train_accuracy = accuracy_score(y_train, y_train_pred)\n","print(f\"Accuracy on training data: {train_accuracy:.3f}\")\n","\n","# Make predictions on the test set\n","start_time = time.time()\n","y_pred = rf_random.predict(A_test)\n","predict_time = time.time() - start_time\n","\n","print(f\"Prediction time: {predict_time:.2f} seconds\")\n","\n","# Calculate and print test accuracy\n","test_accuracy = accuracy_score(b_test, y_pred)\n","print(f\"Accuracy on test data: {test_accuracy:.3f}\")\n","\n","# Print the classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(b_test, y_pred))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Learning Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import learning_curve\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n","def plot_learning_curve(estimator, X, y, title):\n","    train_sizes, train_scores, test_scores = learning_curve(\n","        estimator, X, y, cv=5, n_jobs=-1, \n","        train_sizes=np.linspace(0.1, 1.0, 10),\n","        scoring='accuracy'\n","    )\n","    \n","    train_mean = np.mean(train_scores, axis=1)\n","    train_std = np.std(train_scores, axis=1)\n","    test_mean = np.mean(test_scores, axis=1)\n","    test_std = np.std(test_scores, axis=1)\n","    \n","    plt.figure(figsize=(10, 6))\n","    plt.title(title)\n","    plt.xlabel(\"Training examples\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.grid()\n","    \n","    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n","    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n","    plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n","    plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n","    \n","    plt.legend(loc=\"best\")\n","    plt.show()\n","\n","rf_random = RandomForestClassifier(n_estimators=100, random_state=42)\n","plot_learning_curve(random_rf, X, y, \"Learning Curve - Random Forest\")\n","\n","plot_learning_curve(best_knn, X, y, \"Learning Curve - KNN\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Cross validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-11T15:34:19.204309Z","iopub.status.idle":"2024-10-11T15:34:19.205010Z","shell.execute_reply":"2024-10-11T15:34:19.204787Z","shell.execute_reply.started":"2024-10-11T15:34:19.204757Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification  # For generating a more realistic dataset\n","\n","def evaluate_model(X, y, model, n_splits=5):\n","    # Initialize the StratifiedKFold\n","    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    \n","    # Initialize lists to store the results\n","    accuracies = []\n","    precisions = []\n","    recalls = []\n","    f1_scores = []\n","    \n","    # Initialize the scaler\n","    scaler = StandardScaler()\n","    \n","    # Perform k-fold cross-validation\n","    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n","        # Split the data\n","        X_train, X_val = X[train_index], X[val_index]\n","        y_train, y_val = y[train_index], y[val_index]\n","        \n","        # Scale the features\n","        X_train_scaled = scaler.fit_transform(X_train)\n","        X_val_scaled = scaler.transform(X_val)\n","        \n","        # Train the model\n","        best_rf.fit(X_train_scaled, y_train)\n","        \n","        # Make predictions\n","        y_pred = best_rf.predict(X_val_scaled)\n","        \n","        # Calculate metrics\n","        accuracies.append(accuracy_score(y_val, y_pred))\n","        precisions.append(precision_score(y_val, y_pred, average='weighted'))\n","        recalls.append(recall_score(y_val, y_pred, average='weighted'))\n","        f1_scores.append(f1_score(y_val, y_pred, average='weighted'))\n","        \n","        print(f\"Fold {fold} - Accuracy: {accuracies[-1]:.4f}, Precision: {precisions[-1]:.4f}, \"\n","              f\"Recall: {recalls[-1]:.4f}, F1-score: {f1_scores[-1]:.4f}\")\n","    \n","    # Calculate and print average metrics\n","    print(\"\\nAverage metrics:\")\n","    print(f\"Accuracy: {np.mean(accuracies):.4f} (+/- {np.std(accuracies):.4f})\")\n","    print(f\"Precision: {np.mean(precisions):.4f} (+/- {np.std(precisions):.4f})\")\n","    print(f\"Recall: {np.mean(recalls):.4f} (+/- {np.std(recalls):.4f})\")\n","    print(f\"F1-score: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Generate a more realistic dataset\n","    X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, \n","                               n_redundant=5, n_classes=2, random_state=42)\n","    \n","    # Initialize your model (replace with your actual model if needed)\n","    model = RandomForestClassifier(n_estimators=100, random_state=42)\n","    \n","    # Evaluate the model\n","    evaluate_model(X, y, model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_validate\n","from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","def evaluate_knn(X, y, n_neighbors=5, weights='uniform', cv=5):\n","    # Initialize the KNN model\n","    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n","\n","    # Define the scoring metrics\n","    scoring = {\n","        'accuracy': 'accuracy',\n","        'precision': make_scorer(precision_score, average='weighted'),\n","        'recall': make_scorer(recall_score, average='weighted'),\n","        'f1': make_scorer(f1_score, average='weighted')\n","    }\n","    \n","    # Perform cross-validation\n","    results = cross_validate(knn, X, y, cv=cv, scoring=scoring)\n","    \n","    # Print results\n","    print(f\"KNN (n_neighbors={n_neighbors}, weights={weights}):\")\n","    for metric in scoring.keys():\n","        scores = results[f'test_{metric}']\n","        print(f\"{metric.capitalize()}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n","    print()\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    from sklearn.datasets import make_classification\n","    \n","    # Generate a sample dataset (replace with your actual data)\n","    X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.7, 0.3], \n","                               n_features=20, random_state=42)\n","    \n","    # Normalize the features\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    \n","    # Evaluate KNN with different parameters\n","    evaluate_knn(X_scaled, y, n_neighbors=3)\n","    evaluate_knn(X_scaled, y, n_neighbors=5)\n","    evaluate_knn(X_scaled, y, n_neighbors=11)\n","    evaluate_knn(X_scaled, y, n_neighbors=7, weights='distance')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-10-11T15:34:19.213450Z","iopub.status.idle":"2024-10-11T15:34:19.213912Z","shell.execute_reply":"2024-10-11T15:34:19.213705Z","shell.execute_reply.started":"2024-10-11T15:34:19.213683Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Initialize stratified k-fold\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Initialize lists to store the scores\n","accuracies = []\n","precisions = []\n","recalls = []\n","f1_scores = []\n","\n","# Perform cross-validation\n","for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n","    X_train_fold, X_val_fold = X[train_index], X[val_index]\n","    y_train_fold, y_val_fold = y[train_index], y[val_index]\n","    \n","    # Train the model\n","    model1.fit(X_train_fold, y_train_fold)\n","    \n","    # Make predictions\n","    y_pred = model1.predict(X_val_fold)\n","    \n","    # Calculate scores\n","    accuracies.append(accuracy_score(y_val_fold, y_pred))\n","    precisions.append(precision_score(y_val_fold, y_pred, average='weighted'))\n","    recalls.append(recall_score(y_val_fold, y_pred, average='weighted'))\n","    f1_scores.append(f1_score(y_val_fold, y_pred, average='weighted'))\n","\n","# Calculate mean scores\n","mean_accuracy = np.mean(accuracies)\n","mean_precision = np.mean(precisions)\n","mean_recall = np.mean(recalls)\n","mean_f1 = np.mean(f1_scores)\n","\n","print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n","print(f\"Mean Precision: {mean_precision:.4f}\")\n","print(f\"Mean Recall: {mean_recall:.4f}\")\n","print(f\"Mean F1-score: {mean_f1:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Model Evaluation**"]},{"cell_type":"markdown","metadata":{},"source":["Confusion matrix, Classification Report, Error-rate and execution time"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T16:03:45.307035Z","iopub.status.busy":"2024-10-11T16:03:45.306599Z","iopub.status.idle":"2024-10-11T16:03:53.092760Z","shell.execute_reply":"2024-10-11T16:03:53.091407Z","shell.execute_reply.started":"2024-10-11T16:03:45.306998Z"},"trusted":true},"outputs":[],"source":["import time\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","\n","# Assuming best_knn and best_rf are your tuned models\n","best_rf = rf_random\n","models = {\n","    'KNN': best_knn,\n","    'Random Forest': best_rf\n","}\n","\n","for name, model in models.items():\n","    print(f\"\\n{name} Model Evaluation:\")\n","    \n","    # Start timing\n","    start_time = time.time()\n","    \n","    # Make predictions\n","    y_pred = model.predict(A_test)\n","    \n","    # End timing\n","    end_time = time.time()\n","    \n","    # Confusion Matrix\n","    cm = confusion_matrix(b_test, y_pred)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","    \n","    # Visualize Confusion Matrix\n","    plt.figure(figsize=(10,7))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title(f'Confusion Matrix - {name}')\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    plt.show()\n","    \n","    # Error Rate\n","    error_rate = 1 - accuracy_score(b_test, y_pred)\n","    print(f\"Error Rate: {error_rate:.4f}\")\n","    \n","    # Execution Time\n","    execution_time = end_time - start_time\n","    print(f\"Execution Time: {execution_time:.4f} seconds\")\n","    \n","    # Classification Report\n","    cr = classification_report(b_test, y_pred)\n","    print(\"Classification Report:\")\n","    print(cr)"]},{"cell_type":"markdown","metadata":{},"source":["Balanced Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T16:03:32.708259Z","iopub.status.busy":"2024-10-11T16:03:32.707826Z","iopub.status.idle":"2024-10-11T16:03:32.717808Z","shell.execute_reply":"2024-10-11T16:03:32.716471Z","shell.execute_reply.started":"2024-10-11T16:03:32.708221Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","def balanced_accuracy(confusion_matrix):\n","    tn, fp, fn, tp = confusion_matrix.ravel()\n","    sensitivity = tp / (tp + fn)\n","    specificity = tn / (tn + fp)\n","    return (sensitivity + specificity) / 2\n","\n","# KNN confusion matrix\n","cm_knn = np.array([[11414, 1021],\n","                   [1474, 2372]])\n","\n","# Random Forest confusion matrix\n","cm_rf = np.array([[11679, 756],\n","                  [1507, 2339]])\n","\n","ba_knn = balanced_accuracy(cm_knn)\n","ba_rf = balanced_accuracy(cm_rf)\n","\n","print(f\"Balanced Accuracy for KNN: {ba_knn:.4f}\")\n","print(f\"Balanced Accuracy for Random Forest: {ba_rf:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["ROC curve"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T16:04:12.501178Z","iopub.status.busy":"2024-10-11T16:04:12.500351Z","iopub.status.idle":"2024-10-11T16:04:19.128971Z","shell.execute_reply":"2024-10-11T16:04:19.127782Z","shell.execute_reply.started":"2024-10-11T16:04:12.501130Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","# Assuming best_knn and best_rf are your tuned models\n","# and A_test and b_test are your test data\n","best_rf = rf_random\n","# KNN predictions\n","y_pred_proba_knn = best_knn.predict_proba(A_test)[:, 1]\n","fpr_knn, tpr_knn, _ = roc_curve(b_test, y_pred_proba_knn)\n","roc_auc_knn = auc(fpr_knn, tpr_knn)\n","\n","# Random Forest predictions\n","y_pred_proba_rf = best_rf.predict_proba(A_test)[:, 1]\n","fpr_rf, tpr_rf, _ = roc_curve(b_test, y_pred_proba_rf)\n","roc_auc_rf = auc(fpr_rf, tpr_rf)\n","\n","# Plot ROC curves\n","plt.figure(figsize=(10, 8))\n","plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2,\n","         label='KNN (AUC = %0.2f)' % roc_auc_knn)\n","plt.plot(fpr_rf, tpr_rf, color='darkgreen', lw=2,\n","         label='Random Forest (AUC = %0.2f)' % roc_auc_rf)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","print(f\"AUC for KNN: {roc_auc_knn:.4f}\")\n","print(f\"AUC for Random Forest: {roc_auc_rf:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Confidence Interval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T16:20:04.437198Z","iopub.status.busy":"2024-10-11T16:20:04.436752Z","iopub.status.idle":"2024-10-11T16:28:21.787277Z","shell.execute_reply":"2024-10-11T16:28:21.785709Z","shell.execute_reply.started":"2024-10-11T16:20:04.437159Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","from scipy import stats\n","from joblib import Parallel, delayed\n","\n","def bootstrap_confidence_interval(model, X, y, n_iterations=200, ci=0.95, n_jobs=-1, sample_size=10000):\n","    n_samples = min(len(y), sample_size)\n","    \n","    def single_bootstrap(seed):\n","        np.random.seed(seed)\n","        indices = np.random.randint(0, len(y), n_samples)\n","        X_bootstrap = X[indices] if isinstance(X, np.ndarray) else X.iloc[indices].values\n","        y_bootstrap = y[indices] if isinstance(y, np.ndarray) else y.iloc[indices].values\n","        y_pred = model.predict(X_bootstrap)\n","        return accuracy_score(y_bootstrap, y_pred)\n","    \n","    accuracies = Parallel(n_jobs=n_jobs)(delayed(single_bootstrap)(i) for i in range(n_iterations))\n","    \n","    lower_bound, upper_bound = np.percentile(accuracies, [(1-ci)/2 * 100, (1+ci)/2 * 100])\n","    return np.mean(accuracies), lower_bound, upper_bound\n","\n","# Assuming best_knn and best_rf are your tuned models\n","# and A_test, b_test are your test data\n","\n","# For KNN\n","knn_mean, knn_lower, knn_upper = bootstrap_confidence_interval(best_knn, A_test, b_test)\n","print(f\"KNN Accuracy: {knn_mean:.4f} (95% CI: {knn_lower:.4f} - {knn_upper:.4f})\")\n","\n","# For Random Forest\n","rf_mean, rf_lower, rf_upper = bootstrap_confidence_interval(best_rf, A_test, b_test)\n","print(f\"Random Forest Accuracy: {rf_mean:.4f} (95% CI: {rf_lower:.4f} - {rf_upper:.4f})\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Final Execution Time "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","import numpy as np\n","\n","# Assuming A_test is your test feature set\n","\n","# Function to measure execution time\n","def measure_execution_time(model, X_test, n_runs=10):\n","    times = []\n","    for _ in range(n_runs):\n","        start_time = time.time()\n","        model.predict(X_test)\n","        end_time = time.time()\n","        times.append(end_time - start_time)\n","    return np.mean(times), np.std(times)\n","\n","# Measure execution time for Random Forest\n","rf_mean_time, rf_std_time = measure_execution_time(best_rf, A_test)\n","\n","# Measure execution time for KNN\n","knn_mean_time, knn_std_time = measure_execution_time(best_knn, A_test)\n","\n","# Print results\n","print(f\"Random Forest Execution Time: {rf_mean_time:.4f} ± {rf_std_time:.4f} seconds\")\n","print(f\"KNN Execution Time: {knn_mean_time:.4f} ± {knn_std_time:.4f} seconds\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":485056,"sourceId":904939,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"dm-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
